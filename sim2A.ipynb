{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little bit of theory:\n",
    "\n",
    "**Transfer entropy**: the mutual information between $Y_{pres}$ and $X_{past}$, conditioned on $Y_{past}$\n",
    "\n",
    "$$ TE(X\\rightarrow Y) = I(X_{past}; Y_{pres}|Y_{past}) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ I(S=s,X_i) = \\sum_{x_i \\in X_i} p(x_i|s)\\,\\log\\frac{p(s|x_i)}{p(s)}$$\n",
    "\n",
    "is the specific information that the source $X_i$ carries about a specific outcome of the target variable $s\\in S$.\n",
    "\n",
    "**FIT**:\n",
    "\n",
    "$$ FIT = \\text{min}[SUI(S: X_{past}, Y_{pres} \\ Y_{past} ),\\, SUI(Y_{pres}: X_{past}, S\\ Y_{past})] $$\n",
    "\n",
    "where \n",
    "- $SUI(S: X_{past}, Y_{pres} \\ Y_{past} )$ is the information about $S$ that $X_{past}$ shares with $Y_{pres}$ and it's unique with respect to $Y_{past}$ and it's defined as the difference between the shared information that $X_{past}, Y_{pres}$ carry about $S$ and the shared information that $X_{past}, Y_{pres}$ and $Y_{past}$ carry about $S$\n",
    "- $SUI(Y_{pres}: X_{past}, S\\ Y_{past})$ is the information about $Y_{pres}$ that $X_{past}$ shares with $S$ and it's unique with respect to $Y_{past}$\n",
    "\n",
    "Moreover\n",
    "\n",
    "$$ SUI(S:X_1,X_2) = \\sum_{s\\in S} p(s) \\text{min}_{X_i \\in \\{ X_1, X_2\\} } I(S=s,X_i) $$\n",
    "\n",
    "is the shared information that $X_1$ and $X_2$ carry about $S$.\n",
    "\n",
    "**Sender activity**: 2D variable\n",
    "\n",
    "$$X(t)_{stim} = S(t)(1+N(0, \\sigma_{stim}))$$\n",
    "\n",
    "where $S(t)$ is a step function equal to the value of the stimulus $s \\in [1,4]$ during the time window $[200,250]\\,ms$.\n",
    "\n",
    "$$X(t)_{noise} = N(0,\\sigma)$$\n",
    "\n",
    "**Receiver activity**: 1D variable\n",
    "\n",
    "$$Y(t) = W_{stim}X_{stim}(t-\\delta) + W_{noise}X_{noise}(t-\\delta) + N(0,\\sigma)$$\n",
    "\n",
    "where the **delay** $\\delta$ is chosen randomly from a uniform distribution in $[40,60]\\,ms$ in step of $10\\,ms$, moreover $\\sigma = 2$ and $\\sigma_{stim} = \\sigma/5 = 0.4$.\n",
    "\n",
    "**Numerical computation of FIT**: discretization of neural activity into a number R of equipopulated bins and empirical computation of the occurence frequency of each binned response across all available trials.\n",
    "\n",
    "FIT/TE are computed at the first time instant in which $Y$ received information from $X$.\n",
    "\n",
    "Total of 50 simulation with 500 trials per stimulus each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT TO DO\n",
    "\n",
    "- **Fig. 2A**: evaluation of FIT and TE for each value of $W_{noise}$ and $W_{stim}$\n",
    "- **Fig. 2B**: FIT and TE as a function of time with $W_{stim}=0.5$ and $W_{noise}=1$ (FIT/TE values computed at all points and averaged over delays to obtain temporal profiles of transmitted information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrials_per_stim = 50      # number of trials for each simulation\n",
    "simReps = 10                # number of simulations\n",
    "nShuff = 10                 # number of permutations\n",
    "\n",
    "w_sig = np.linspace(0, 1, num=11)      # signal weights for Y computation\n",
    "w_noise = np.linspace(0, 1, num=11)    # noise weights for Y computation\n",
    "stdX_noise = 2                      # std of gaussian noise in X_noise\n",
    "stdY = 2                            # std of gaussian noise in Y\n",
    "ratio = 0.2                         # ratio between stdX_sig and stdX_noise\n",
    "stdX_sig = ratio * stdX_noise       # std of gaussian noise in X_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simLen = 60                             # simulation length in units of 10 ms\n",
    "stimWin = [30, 35]                      # X stimulus encoding window in units of 10 ms\n",
    "delays = np.linspace(4, 6, num=3, dtype=int)\n",
    "n_binsS = 4                             # number of stimulus values\n",
    "n_binsX = 3\n",
    "n_binsY = 3\n",
    "eps = 1e-52                             # infinitesimal value\n",
    "\n",
    "nTrials = nTrials_per_stim * n_binsS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw random delay for each simulation repetition\n",
    "reps_delays = npr.choice(delays, simReps, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.full((simReps, len(w_sig), len(w_noise)), np.nan)\n",
    "di = fit.copy()\n",
    "dfi = fit.copy()\n",
    "fitsh = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish = fitsh.copy()\n",
    "dfish = fitsh.copy()\n",
    "fitsh_cond = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish_cond = fitsh_cond.copy()\n",
    "dfish_cond = fitsh_cond.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation number:  0 \n",
      "\n",
      "Simulation number:  1 \n",
      "\n",
      "Simulation number:  2 \n",
      "\n",
      "Simulation number:  3 \n",
      "\n",
      "Simulation number:  4 \n",
      "\n",
      "Simulation number:  5 \n",
      "\n",
      "Simulation number:  6 \n",
      "\n",
      "Simulation number:  7 \n",
      "\n",
      "Simulation number:  8 \n",
      "\n",
      "Simulation number:  9 \n",
      "\n",
      "Simulation number:  10 \n",
      "\n",
      "Simulation number:  11 \n",
      "\n",
      "Simulation number:  12 \n",
      "\n",
      "Simulation number:  13 \n",
      "\n",
      "Simulation number:  14 \n",
      "\n",
      "Simulation number:  15 \n",
      "\n",
      "Simulation number:  16 \n",
      "\n",
      "Simulation number:  17 \n",
      "\n",
      "Simulation number:  18 \n",
      "\n",
      "Simulation number:  19 \n",
      "\n",
      "Simulation number:  20 \n",
      "\n",
      "Simulation number:  21 \n",
      "\n",
      "Simulation number:  22 \n",
      "\n",
      "Simulation number:  23 \n",
      "\n",
      "Simulation number:  24 \n",
      "\n",
      "Simulation number:  25 \n",
      "\n",
      "Simulation number:  26 \n",
      "\n",
      "Simulation number:  27 \n",
      "\n",
      "Simulation number:  28 \n",
      "\n",
      "Simulation number:  29 \n",
      "\n",
      "Simulation number:  30 \n",
      "\n",
      "Simulation number:  31 \n",
      "\n",
      "Simulation number:  32 \n",
      "\n",
      "Simulation number:  33 \n",
      "\n",
      "Simulation number:  34 \n",
      "\n",
      "Simulation number:  35 \n",
      "\n",
      "Simulation number:  36 \n",
      "\n",
      "Simulation number:  37 \n",
      "\n",
      "Simulation number:  38 \n",
      "\n",
      "Simulation number:  39 \n",
      "\n",
      "Simulation number:  40 \n",
      "\n",
      "Simulation number:  41 \n",
      "\n",
      "Simulation number:  42 \n",
      "\n",
      "Simulation number:  43 \n",
      "\n",
      "Simulation number:  44 \n",
      "\n",
      "Simulation number:  45 \n",
      "\n",
      "Simulation number:  46 \n",
      "\n",
      "Simulation number:  47 \n",
      "\n",
      "Simulation number:  48 \n",
      "\n",
      "Simulation number:  49 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for simIdx in range(simReps):\n",
    "    print('Simulation number: ', simIdx, '\\n')\n",
    "    for sigIdx in range(len(w_sig)):\n",
    "        for noiseIdx in range(len(w_noise)):\n",
    "            # draw the stimulus value for each trial\n",
    "            S = npr.randint(1, n_binsS + 1, size=nTrials)\n",
    "\n",
    "            # simulate neural activity\n",
    "            X_noise = npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Noise time series\n",
    "        \n",
    "            X_signal = eps * npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Infinitesimal signal to avoid binning \n",
    "\n",
    "            X_signal[stimWin[0]:stimWin[1],:] = np.tile(S, (stimWin[1]-stimWin[0], 1)) # Assigning Stimulus to Window\n",
    "\n",
    "            # Adding multiplicative noise (we changed the dimension from nTrials to (simLen, nTrials) to have a different error for each time step)\n",
    "            X_signal = X_signal * (1 + npr.normal(0, stdX_sig, size=(simLen, nTrials))) \n",
    "\n",
    "            # Time lagged single-trial input from the 2 dimensions of X and Y (we multpily everything by the weights, they mutiply only the stim/noise)\n",
    "            X2Ysig = w_sig[sigIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_signal[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "            X2Ynoise = w_noise[noiseIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_noise[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "\n",
    "            # Computing Y + gaussian noise\n",
    "            Y = X2Ysig + X2Ynoise + npr.normal(0,stdY,size=(simLen, nTrials))\n",
    "\n",
    "            # First time point at which Y receives stim info from X\n",
    "            t = stimWin[0] + reps_delays[simIdx]\n",
    "            d = reps_delays[simIdx]\n",
    "\n",
    "            # Discretize Neural Activity\n",
    "            _, bin_edges = pd.qcut(X_noise[t-d,:], n_binsX, retbins=True)\n",
    "            bX_noise = np.digitize(X_noise[t-d, :], bins=bin_edges, right=False)\n",
    "\n",
    "            _, bin_edges = pd.qcut(X_signal[t-d,:], n_binsX, retbins=True)\n",
    "            bX_sig = np.digitize(X_signal[t-d,:], bins=bin_edges, right=False)\n",
    "\n",
    "            _, bin_edges = pd.qcut(Y[t,:], n_binsY, retbins=True)\n",
    "            bYt = np.digitize(Y[t,:], bins=bin_edges, right=False)\n",
    "\n",
    "            _, bin_edges = pd.qcut(Y[t-d,:], n_binsY, retbins=True)\n",
    "            bYpast = np.digitize(Y[t-d,:], bins=bin_edges, right=False)\n",
    "\n",
    "            bx = (bX_sig - 1) * n_binsX + bX_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "[[-9.77442426e-54  3.58433197e-52  1.20897343e-52 ...  2.02674785e-52\n",
      "  -1.36445505e-52 -2.53343960e-52]\n",
      " [-1.56807650e-52  2.18690700e-53 -1.29837535e-52 ... -1.43495403e-52\n",
      "   4.49500021e-53  1.04878661e-52]\n",
      " [ 5.98277173e-53 -4.20367123e-52  2.61021670e-52 ... -1.49064672e-52\n",
      "  -2.45033187e-53  2.94151298e-52]\n",
      " ...\n",
      " [-1.66801829e-53 -1.22987247e-53  4.98928151e-53 ...  4.59914380e-53\n",
      "  -6.62644711e-53 -6.56691048e-53]\n",
      " [ 2.59025823e-53  1.51260117e-53 -1.31211531e-53 ... -2.66455396e-54\n",
      "   4.31468110e-54 -7.74063844e-54]\n",
      " [ 6.97837815e-54 -6.34423549e-54  1.67402663e-54 ...  1.02051195e-53\n",
      "   1.57734201e-53 -2.13863714e-54]]\n"
     ]
    }
   ],
   "source": [
    "S = npr.randint(1, n_binsS + 1, size=nTrials)\n",
    "print(np.shape(S))\n",
    "\n",
    "# simulate neural activity\n",
    "X_noise = npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Noise time series\n",
    "        \n",
    "X_signal = eps * npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Infinitesimal signal to avoid binning \n",
    "\n",
    "X_signal[stimWin[0]:stimWin[1],:] = np.tile(S, (stimWin[1]-stimWin[0], 1)) # Assigning Stimulus to Window\n",
    "\n",
    "# Adding multiplicative noise (we changed the dimension from nTrials to (simLen, nTrials) to have a different error for each time step)\n",
    "X_signal = X_signal * (1 + npr.normal(0, stdX_sig, size=(simLen, nTrials))) \n",
    "\n",
    "#print(np.shape(eps * npr.normal(0, stdX_noise, size=(reps_delays[0], nTrials))))\n",
    "#print(np.shape(w_sig[0] * X_signal[0:len(X_signal)-reps_delays[0],:]))\n",
    "\n",
    "X2Ysig = np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[0], nTrials)),\\\n",
    "                     w_sig[1] * X_signal[0:len(X_signal)-reps_delays[0],:]))\n",
    "print(X2Ysig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
